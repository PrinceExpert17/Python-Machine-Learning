{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d68c116-8216-4d7d-ad43-1524f5090a07",
   "metadata": {
    "id": "A69jIUa4uq3Y"
   },
   "outputs": [],
   "source": [
    "# Iris dataset\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50f8806-e45d-4fd2-82e1-ccaf303d3b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  **Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79fb6a4-e15a-4cbf-a449-207dd4177b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b656d-86ec-468a-8578-a0515ae25821",
   "metadata": {
    "id": "g-NFn_UOtuVE"
   },
   "outputs": [],
   "source": [
    "#b1 = pd.read_csv('PubchemFingerprint_with_class_label.csv')\n",
    "#b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b99fa-0cfd-4624-86ad-dd660950aa08",
   "metadata": {
    "id": "roxPlm8ShaJs"
   },
   "outputs": [],
   "source": [
    "#X = b1.drop('Activity', axis=1)s\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9aee2-458e-4d59-9df1-c3234a83dbb8",
   "metadata": {
    "id": "cyAOBjc5hwf_"
   },
   "outputs": [],
   "source": [
    "#y = b1['Activity'].copy()\n",
    "#y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640316ce-30ac-4085-a4eb-ad8bfb717cd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## **Data Preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "411ee73f-ddec-4a7e-a261-0a9fe5bac297",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9vHDORkwJE5",
    "outputId": "afe2ac6b-c430-4c34-b321-d6c9e7400570"
   },
   "outputs": [],
   "source": [
    "# Remove low variance features\n",
    "selection = VarianceThreshold(threshold=(0.1))    \n",
    "X = selection.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e56630cf-eac7-472a-b140-aa9d07199e4d",
   "metadata": {
    "id": "lpns5FPdaQgq"
   },
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc122a05-9079-4cac-9a36-27511af4dfb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGQmqYf2ObLw",
    "outputId": "46f73cc2-584a-4150-d1b3-759bf777c614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (120, 4), (30, 4)\n",
      "Y: (120,), (30,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X: {X_train.shape}, {X_test.shape}\\nY: {y_train.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e0dab-3dde-4055-8605-7c2c03504a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Building models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9166507-8e86-4d24-8fc0-3fbc059290e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### K-NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5c0f8d0-6ac5-4dcf-bb31-df42cfe62d08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fI6Ni6i3EAy",
    "outputId": "fcd88810-42d7-41d6-d4c4-90d808704f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9666666666666667\n",
      "- MCC: 0.9503960809010947\n",
      "- F1 score: 0.9666458203043571\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9333333333333333\n",
      "- MCC: 0.9060606745389328\n",
      "- F1 score: 0.9326599326599326\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(3) # Define classifier\n",
    "knn.fit(X_train, y_train) # Train model\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "knn_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "knn_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "knn_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "knn_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "knn_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "knn_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % knn_train_accuracy)\n",
    "print('- MCC: %s' % knn_train_mcc)\n",
    "print('- F1 score: %s' % knn_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % knn_test_accuracy)\n",
    "print('- MCC: %s' % knn_test_mcc)\n",
    "print('- F1 score: %s' % knn_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a818633e-56b3-4a72-be77-4fe5ea49167d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SVM (Radial basis function kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e249dbb-2557-4a7d-a3ad-645ada4b15d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9833333333333333\n",
      "- MCC: 0.9754065040827025\n",
      "- F1 score: 0.9833229101521785\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9333333333333333\n",
      "- MCC: 0.9060606745389328\n",
      "- F1 score: 0.9326599326599326\n"
     ]
    }
   ],
   "source": [
    "svm_rbf = SVC(gamma=1, C=2)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = svm_rbf.predict(X_train)\n",
    "y_test_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "svm_rbf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "svm_rbf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "svm_rbf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "svm_rbf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "svm_rbf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "svm_rbf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % svm_rbf_train_accuracy)\n",
    "print('- MCC: %s' % svm_rbf_train_mcc)\n",
    "print('- F1 score: %s' % svm_rbf_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % svm_rbf_test_accuracy)\n",
    "print('- MCC: %s' % svm_rbf_test_mcc)\n",
    "print('- F1 score: %s' % svm_rbf_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9659da3f-f17c-460b-a801-989078b8d79b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b71a1d4-ff98-4c38-8c50-2d8a8a2a850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 1.0\n",
      "- MCC: 1.0\n",
      "- F1 score: 1.0\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9\n",
      "- MCC: 0.8630442403635762\n",
      "- F1 score: 0.8976982097186702\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5) # Define classifier\n",
    "dt.fit(X_train, y_train) # Train model\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "dt_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "dt_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "dt_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "dt_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "dt_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "dt_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % dt_train_accuracy)\n",
    "print('- MCC: %s' % dt_train_mcc)\n",
    "print('- F1 score: %s' % dt_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % dt_test_accuracy)\n",
    "print('- MCC: %s' % dt_test_mcc)\n",
    "print('- F1 score: %s' % dt_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a24d3-0e62-4696-bd8e-c1213bec85fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b34103a0-81d2-47e6-abf8-417cfe2ffb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9916666666666667\n",
      "- MCC: 0.9876028806587153\n",
      "- F1 score: 0.9916653643798511\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9\n",
      "- MCC: 0.8630442403635762\n",
      "- F1 score: 0.8976982097186702\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10) # Define classifier\n",
    "rf.fit(X_train, y_train) # Train model\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "rf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "rf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "rf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "rf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "rf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "rf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % rf_train_accuracy)\n",
    "print('- MCC: %s' % rf_train_mcc)\n",
    "print('- F1 score: %s' % rf_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % rf_test_accuracy)\n",
    "print('- MCC: %s' % rf_test_mcc)\n",
    "print('- F1 score: %s' % rf_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af22d0b-463c-407e-89ff-b05f0b4641f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a7c3e04-8a7a-4270-b46d-127a2fc008b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9833333333333333\n",
      "- MCC: 0.9754065040827025\n",
      "- F1 score: 0.9833229101521785\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9666666666666667\n",
      "- MCC: 0.9515873026942034\n",
      "- F1 score: 0.9665831244778613\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(alpha=1, max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "mlp_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "mlp_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "mlp_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set performance\n",
    "mlp_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "mlp_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "mlp_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % mlp_train_accuracy)\n",
    "print('- MCC: %s' % mlp_train_mcc)\n",
    "print('- F1 score: %s' % mlp_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % mlp_test_accuracy)\n",
    "print('- MCC: %s' % mlp_test_mcc)\n",
    "print('- F1 score: %s' % mlp_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad838bc-e030-4e2c-bc90-22f6e6fec12c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Building stacked model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d1ba8e3-6dcf-48cf-9758-01ee0ab4619f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WO_qR3303OUp",
    "outputId": "985e12c1-9e17-4bd1-f9ca-8d705b47afd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9833333333333333\n",
      "- MCC: 0.9754065040827025\n",
      "- F1 score: 0.9833229101521785\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9333333333333333\n",
      "- MCC: 0.9060606745389328\n",
      "- F1 score: 0.9326599326599326\n"
     ]
    }
   ],
   "source": [
    "# Define estimators\n",
    "estimator_list = [\n",
    "    ('knn',knn),\n",
    "    ('svm_rbf',svm_rbf),\n",
    "    ('dt',dt),\n",
    "    ('rf',rf),\n",
    "    ('mlp',mlp) ]\n",
    "\n",
    "# Build stack model\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=estimator_list, final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = stack_model.predict(X_train)\n",
    "y_test_pred = stack_model.predict(X_test)\n",
    "\n",
    "# Training set model performance\n",
    "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set model performance\n",
    "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
    "print('- MCC: %s' % stack_model_train_mcc)\n",
    "print('- F1 score: %s' % stack_model_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
    "print('- MCC: %s' % stack_model_test_mcc)\n",
    "print('- F1 score: %s' % stack_model_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbad4b-a2e8-4a6c-8c55-6f194e9284c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45b23492-6743-45cc-91a6-5e3ffb4098e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_list = {'knn':knn_train_accuracy,\n",
    "'svm_rbf': svm_rbf_train_accuracy,\n",
    "'dt': dt_train_accuracy,\n",
    "'rf': rf_train_accuracy,\n",
    "'mlp': mlp_train_accuracy,\n",
    "'stack': stack_model_train_accuracy}\n",
    "\n",
    "mcc_train_list = {'knn':knn_train_mcc,\n",
    "'svm_rbf': svm_rbf_train_mcc,\n",
    "'dt': dt_train_mcc,\n",
    "'rf': rf_train_mcc,\n",
    "'mlp': mlp_train_mcc,\n",
    "'stack': stack_model_train_mcc}\n",
    "\n",
    "f1_train_list = {'knn':knn_train_f1,\n",
    "'svm_rbf': svm_rbf_train_f1,\n",
    "'dt': dt_train_f1,\n",
    "'rf': rf_train_f1,\n",
    "'mlp': mlp_train_f1,\n",
    "'stack': stack_model_train_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d31fb1fa-e2e3-4243-9c12-3072b09739de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn': 0.9666666666666667,\n",
       " 'svm_rbf': 0.9833333333333333,\n",
       " 'dt': 1.0,\n",
       " 'rf': 0.9916666666666667,\n",
       " 'mlp': 0.9833333333333333,\n",
       " 'stack': 0.9833333333333333}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "750e6d2d-d56c-4adf-a833-4d471ffd6328",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "RrUnYrWj3p-s",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8e74df8b-3661-42f1-c339-3a288e28c3de",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn': 0.9503960809010947,\n",
       " 'svm_rbf': 0.9754065040827025,\n",
       " 'dt': 1.0,\n",
       " 'rf': 0.9876028806587153,\n",
       " 'mlp': 0.9754065040827025,\n",
       " 'stack': 0.9754065040827025}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fc461dc-5de8-47a4-b4eb-3f89bca6964a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.950396</td>\n",
       "      <td>0.966646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_rbf</th>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975407</td>\n",
       "      <td>0.983323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.987603</td>\n",
       "      <td>0.991665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975407</td>\n",
       "      <td>0.983323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stack</th>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975407</td>\n",
       "      <td>0.983323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy       MCC        F1\n",
       "knn      0.966667  0.950396  0.966646\n",
       "svm_rbf  0.983333  0.975407  0.983323\n",
       "dt       1.000000  1.000000  1.000000\n",
       "rf       0.991667  0.987603  0.991665\n",
       "mlp      0.983333  0.975407  0.983323\n",
       "stack    0.983333  0.975407  0.983323"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.DataFrame.from_dict(acc_train_list, orient='index', columns=['Accuracy'])\n",
    "mcc_df = pd.DataFrame.from_dict(mcc_train_list, orient='index', columns=['MCC'])\n",
    "f1_df = pd.DataFrame.from_dict(f1_train_list, orient='index', columns=['F1'])\n",
    "df = pd.concat([acc_df, mcc_df, f1_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "093479a5-5821-45da-a59a-fbd77581f73b",
   "metadata": {
    "id": "IVz6u1opkzyw"
   },
   "outputs": [],
   "source": [
    "df.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89240bef-8bc0-4f30-afd1-f19dc362f7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568dc52e-04cd-4ba3-bf8a-3bf3b555a42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b34d9e-0041-4949-9c8b-5a6b2d2908f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
